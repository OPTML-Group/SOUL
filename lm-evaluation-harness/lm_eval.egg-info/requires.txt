accelerate>=0.21.0
evaluate
datasets>=2.0.0
evaluate>=0.4.0
jsonlines
numexpr
peft>=0.2.0
pybind11>=2.6.2
pytablewriter
rouge-score>=0.0.4
sacrebleu>=1.5.0
scikit-learn>=0.24.1
sqlitedict
torch>=1.8
tqdm-multiprocess
transformers>=4.1
zstandard

[all]
lm_eval[dev]
lm_eval[testing]
lm_eval[linting]
lm_eval[multilingual]
lm_eval[sentencepiece]
lm_eval[promptsource]
lm_eval[gptq]
lm_eval[anthropic]
lm_eval[openai]
lm_eval[vllm]
lm_eval[ifeval]

[anthropic]
anthropic

[dev]
black
flake8
pre-commit
pytest
pytest-cov

[gptq]
auto-gptq[triton]@ git+https://github.com/PanQiWei/AutoGPTQ

[ifeval]
langdetect
immutabledict

[linting]
flake8
pylint
mypy
pre-commit

[math]
sympy>=1.12
antlr4-python3-runtime==4.11

[multilingual]
nagisa>=0.2.7
jieba>=0.42.1
pycountry

[openai]
openai==1.3.9
tiktoken

[promptsource]
promptsource@ git+https://github.com/bigscience-workshop/promptsource.git#egg=promptsource

[sentencepiece]
sentencepiece>=0.1.98
protobuf>=4.22.1

[testing]
pytest
pytest-cov
pytest-xdist

[vllm]
vllm
